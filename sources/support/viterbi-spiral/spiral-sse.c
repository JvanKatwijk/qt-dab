/***************************************************************
This code was generated by Spiral 6.0 beta, www.spiral.net --
Copyright (c) 2005-2008, Carnegie Mellon University.
All rights reserved.
The code is distributed under the GNU General Public License (GPL)
(see http://www.gnu.org/copyleft/gpl.html)

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
*AS IS* AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
******************************************************************/

//#include <include/mm_malloc.h>
//#include <pmmintrin.h>
#include <emmintrin.h>
#include <xmmintrin.h>
#include <mmintrin.h>
#include	"spiral-sse.h"
void init_FULL_SPIRAL() {
}

//void FULL_SPIRAL_sse(int amount, int32_t  *Y, int32_t  *X, int32_t  *syms, unsigned char  *dec, int32_t  *Branchtab) {
void FULL_SPIRAL_sse(int amount, COMPUTETYPE  *Y,
	                         COMPUTETYPE  *X, 
	                         COMPUTETYPE  *syms, 
	                         DECISIONTYPE  *dec,
	                         COMPUTETYPE  *Branchtab) {
int i9;
//    for(i9 = 0; i9 <= amount; i9++) {
    for(i9 = 0; i9 < amount; i9++) {
        int32_t a1002, a1006, a1010, a1014, a822, a828, a834
                , a840;
        int a820, a850;
        unsigned char s118, s125, s132, s139, s146, s153, s160
                , s167, s174, s181, s188, s195, s202, s209, s216
                , s223;
        int32_t  *a1001, *a1005, *a1009, *a1013, *a821, *a827, *a833
                , *a839, *b104;
        unsigned char  *a1021, *a1030, *a1039, *a1048, *a1057, *a1066, *a1075
                , *a1084, *a849, *a851, *a872, *a893, *a914, *a935, *a956
                , *a977, *a998;
        __m128i  *a1000, *a818, *a819, *a824, *a830, *a836, *a842
                , *a852, *a853, *a854, *a855, *a856, *a859, *a862, *a865
                , *a873, *a874, *a875, *a876, *a877, *a880, *a883, *a886
                , *a894, *a895, *a896, *a897, *a898, *a901, *a904, *a907
                , *a915, *a916, *a917, *a918, *a919, *a922, *a925, *a928
                , *a936, *a937, *a938, *a939, *a940, *a943, *a946, *a949
                , *a957, *a958, *a959, *a960, *a961, *a964, *a967, *a970
                , *a978, *a979, *a980, *a981, *a982, *a985, *a988, *a991
                , *a999;
        __m128i a1003, a1004, a1007, a1008, a1011, a1012, a1015
                , a1016, a1017, a1018, a1019, a1020, a1022, a1023, a1024
                , a1025, a1026, a1027, a1028, a1029, a1031, a1032, a1033
                , a1034, a1035, a1036, a1037, a1038, a1040, a1041, a1042
                , a1043, a1044, a1045, a1046, a1047, a1049, a1050, a1051
                , a1052, a1053, a1054, a1055, a1056, a1058, a1059, a1060
                , a1061, a1062, a1063, a1064, a1065, a1067, a1068, a1069
                , a1070, a1071, a1072, a1073, a1074, a1076, a1077, a1078
                , a1079, a1080, a1081, a1082, a1083, a823, a825, a826
                , a829, a831, a832, a835, a837, a838, a841, a843
                , a844, a845, a846, a847, a848, a857, a858, a860
                , a861, a863, a864, a866, a867, a868, a869, a870
                , a871, a878, a879, a881, a882, a884, a885, a887
                , a888, a889, a890, a891, a892, a899, a900, a902
                , a903, a905, a906, a908, a909, a910, a911, a912
                , a913, a920, a921, a923, a924, a926, a927, a929
                , a930, a931, a932, a933, a934, a941, a942, a944
                , a945, a947, a948, a950, a951, a952, a953, a954
                , a955, a962, a963, a965, a966, a968, a969, a971
                , a972, a973, a974, a975, a976, a983, a984, a986
                , a987, a989, a990, a992, a993, a994, a995, a996
                , a997, b105, b106, b107, b108, b109, b110, b111
                , b112, b113, b114, b115, b116, b117, b118, b119
                , b120, b121, b122, b123, b124, b125, b126, b127
                , b128, b129, b130, b131, b132, b133, b134, b135
                , b136, d37, d38, d39, d40, d41, d42, d43
                , d44, d45, d46, d47, d48, d49, d50, d51
                , d52, d53, d54, d55, d56, d57, d58, d59
                , d60, d61, d62, d63, d64, d65, d66, d67
                , d68, m100, m101, m102, m103, m104, m105, m106
                , m107, m108, m109, m110, m111, m112, m113, m114
                , m115, m116, m117, m118, m119, m120, m121, m122
                , m123, m124, m125, m126, m127, m128, m129, m130
                , m131, m132, m133, m134, m135, m136, m73, m74
                , m75, m76, m77, m78, m79, m80, m81, m82
                , m83, m84, m85, m86, m87, m88, m89, m90
                , m91, m92, m93, m94, m95, m96, m97, m98
                , m99, s114, s115, s116, s117, s119, s120, s121
                , s122, s123, s124, s126, s127, s128, s129, s130
                , s131, s133, s134, s135, s136, s137, s138, s140
                , s141, s142, s143, s144, s145, s147, s148, s149
                , s150, s151, s152, s154, s155, s156, s157, s158
                , s159, s161, s162, s163, s164, s165, s166, s168
                , s169, s170, s171, s172, s173, s175, s176, s177
                , s178, s179, s180, s182, s183, s184, s185, s186
                , s187, s189, s190, s191, s192, s193, s194, s196
                , s197, s198, s199, s200, s201, s203, s204, s205
                , s206, s207, s208, s210, s211, s212, s213, s214
                , s215, s217, s218, s219, s220, s221, s222, s224
                , s225, t39, t40, t41, t42, t43, t44, t45
                , t46, t47, t48, t49, t50, t51, t52, t53
                , t54, t55, t56, t57, t58, t59, t60, t61
                , t62, t63, t64, t65, t66, t67, t68, t69
                , t70;
        a818 = ((__m128i  *) X);
        s114 = *(a818);
        a819 = (a818 + 8);
        s115 = *(a819);
        a820 = (8 * i9);
        a821 = (syms + a820);
        a822 = *(a821);
        a823 = _mm_set1_epi32(a822);
        a824 = ((__m128i  *) Branchtab);
        a825 = *(a824);
        a826 = _mm_xor_si128(a823, a825);
        b104 = (a820 + syms);
        a827 = (b104 + 1);
        a828 = *(a827);
        a829 = _mm_set1_epi32(a828);
        a830 = (a824 + 8);
        a831 = *(a830);
        a832 = _mm_xor_si128(a829, a831);
        a833 = (b104 + 2);
        a834 = *(a833);
        a835 = _mm_set1_epi32(a834);
        a836 = (a824 + 16);
        a837 = *(a836);
        a838 = _mm_xor_si128(a835, a837);
        a839 = (b104 + 3);
        a840 = *(a839);
        a841 = _mm_set1_epi32(a840);
        a842 = (a824 + 24);
        a843 = *(a842);
        a844 = _mm_xor_si128(a841, a843);
        b105 = _mm_add_epi32(a826, a832);
        b106 = _mm_add_epi32(b105, a838);
        t39 = _mm_add_epi32(b106, a844);
        t40 = _mm_sub_epi32(_mm_set_epi32(1020, 1020, 1020, 1020), t39);
        m73 = _mm_add_epi32(s114, t39);
        m74 = _mm_add_epi32(s115, t40);
        m75 = _mm_add_epi32(s114, t40);
        m76 = _mm_add_epi32(s115, t39);
        d37 = _mm_cmpgt_epi32(m73, m74);
        d38 = _mm_cmpgt_epi32(m75, m76);
        a845 = _mm_andnot_si128(d37, m73);
        a846 = _mm_and_si128(d37, m74);
        s116 = _mm_or_si128(a845, a846);
        a847 = _mm_andnot_si128(d38, m75);
        a848 = _mm_and_si128(d38, m76);
        s117 = _mm_or_si128(a847, a848);
        s118 = _mm_movemask_epi8(_mm_packs_epi16(_mm_unpacklo_epi16(_mm_packs_epi16(d37,_mm_setzero_si128()),_mm_packs_epi16(d38,_mm_setzero_si128())),_mm_setzero_si128()));
        a849 = ((unsigned char  *) dec);
        a850 = (16 * i9);
        a851 = (a849 + a850);
        *(a851) = s118;
        s119 = _mm_unpacklo_epi32(s116, s117);
        s120 = _mm_unpackhi_epi32(s116, s117);
        a852 = ((__m128i  *) Y);
        *(a852) = s119;
        a853 = (a852 + 1);
        *(a853) = s120;
        a854 = (a818 + 1);
        s121 = *(a854);
        a855 = (a818 + 9);
        s122 = *(a855);
        a856 = (a824 + 1);
        a857 = *(a856);
        a858 = _mm_xor_si128(a823, a857);
        a859 = (a824 + 9);
        a860 = *(a859);
        a861 = _mm_xor_si128(a829, a860);
        a862 = (a824 + 17);
        a863 = *(a862);
        a864 = _mm_xor_si128(a835, a863);
        a865 = (a824 + 25);
        a866 = *(a865);
        a867 = _mm_xor_si128(a841, a866);
        b107 = _mm_add_epi32(a858, a861);
        b108 = _mm_add_epi32(b107, a864);
        t41 = _mm_add_epi32(b108, a867);
        t42 = _mm_sub_epi32(_mm_set_epi32(1020, 1020, 1020, 1020), t41);
        m77 = _mm_add_epi32(s121, t41);
        m78 = _mm_add_epi32(s122, t42);
        m79 = _mm_add_epi32(s121, t42);
        m80 = _mm_add_epi32(s122, t41);
        d39 = _mm_cmpgt_epi32(m77, m78);
        d40 = _mm_cmpgt_epi32(m79, m80);
        a868 = _mm_andnot_si128(d39, m77);
        a869 = _mm_and_si128(d39, m78);
        s123 = _mm_or_si128(a868, a869);
        a870 = _mm_andnot_si128(d40, m79);
        a871 = _mm_and_si128(d40, m80);
        s124 = _mm_or_si128(a870, a871);
        s125 = _mm_movemask_epi8(_mm_packs_epi16(_mm_unpacklo_epi16(_mm_packs_epi16(d39,_mm_setzero_si128()),_mm_packs_epi16(d40,_mm_setzero_si128())),_mm_setzero_si128()));
        a872 = (a851 + 1);
        *(a872) = s125;
        s126 = _mm_unpacklo_epi32(s123, s124);
        s127 = _mm_unpackhi_epi32(s123, s124);
        a873 = (a852 + 2);
        *(a873) = s126;
        a874 = (a852 + 3);
        *(a874) = s127;
        a875 = (a818 + 2);
        s128 = *(a875);
        a876 = (a818 + 10);
        s129 = *(a876);
        a877 = (a824 + 2);
        a878 = *(a877);
        a879 = _mm_xor_si128(a823, a878);
        a880 = (a824 + 10);
        a881 = *(a880);
        a882 = _mm_xor_si128(a829, a881);
        a883 = (a824 + 18);
        a884 = *(a883);
        a885 = _mm_xor_si128(a835, a884);
        a886 = (a824 + 26);
        a887 = *(a886);
        a888 = _mm_xor_si128(a841, a887);
        b109 = _mm_add_epi32(a879, a882);
        b110 = _mm_add_epi32(b109, a885);
        t43 = _mm_add_epi32(b110, a888);
        t44 = _mm_sub_epi32(_mm_set_epi32(1020, 1020, 1020, 1020), t43);
        m81 = _mm_add_epi32(s128, t43);
        m82 = _mm_add_epi32(s129, t44);
        m83 = _mm_add_epi32(s128, t44);
        m84 = _mm_add_epi32(s129, t43);
        d41 = _mm_cmpgt_epi32(m81, m82);
        d42 = _mm_cmpgt_epi32(m83, m84);
        a889 = _mm_andnot_si128(d41, m81);
        a890 = _mm_and_si128(d41, m82);
        s130 = _mm_or_si128(a889, a890);
        a891 = _mm_andnot_si128(d42, m83);
        a892 = _mm_and_si128(d42, m84);
        s131 = _mm_or_si128(a891, a892);
        s132 = _mm_movemask_epi8(_mm_packs_epi16(_mm_unpacklo_epi16(_mm_packs_epi16(d41,_mm_setzero_si128()),_mm_packs_epi16(d42,_mm_setzero_si128())),_mm_setzero_si128()));
        a893 = (a851 + 2);
        *(a893) = s132;
        s133 = _mm_unpacklo_epi32(s130, s131);
        s134 = _mm_unpackhi_epi32(s130, s131);
        a894 = (a852 + 4);
        *(a894) = s133;
        a895 = (a852 + 5);
        *(a895) = s134;
        a896 = (a818 + 3);
        s135 = *(a896);
        a897 = (a818 + 11);
        s136 = *(a897);
        a898 = (a824 + 3);
        a899 = *(a898);
        a900 = _mm_xor_si128(a823, a899);
        a901 = (a824 + 11);
        a902 = *(a901);
        a903 = _mm_xor_si128(a829, a902);
        a904 = (a824 + 19);
        a905 = *(a904);
        a906 = _mm_xor_si128(a835, a905);
        a907 = (a824 + 27);
        a908 = *(a907);
        a909 = _mm_xor_si128(a841, a908);
        b111 = _mm_add_epi32(a900, a903);
        b112 = _mm_add_epi32(b111, a906);
        t45 = _mm_add_epi32(b112, a909);
        t46 = _mm_sub_epi32(_mm_set_epi32(1020, 1020, 1020, 1020), t45);
        m85 = _mm_add_epi32(s135, t45);
        m86 = _mm_add_epi32(s136, t46);
        m87 = _mm_add_epi32(s135, t46);
        m88 = _mm_add_epi32(s136, t45);
        d43 = _mm_cmpgt_epi32(m85, m86);
        d44 = _mm_cmpgt_epi32(m87, m88);
        a910 = _mm_andnot_si128(d43, m85);
        a911 = _mm_and_si128(d43, m86);
        s137 = _mm_or_si128(a910, a911);
        a912 = _mm_andnot_si128(d44, m87);
        a913 = _mm_and_si128(d44, m88);
        s138 = _mm_or_si128(a912, a913);
        s139 = _mm_movemask_epi8(_mm_packs_epi16(_mm_unpacklo_epi16(_mm_packs_epi16(d43,_mm_setzero_si128()),_mm_packs_epi16(d44,_mm_setzero_si128())),_mm_setzero_si128()));
        a914 = (a851 + 3);
        *(a914) = s139;
        s140 = _mm_unpacklo_epi32(s137, s138);
        s141 = _mm_unpackhi_epi32(s137, s138);
        a915 = (a852 + 6);
        *(a915) = s140;
        a916 = (a852 + 7);
        *(a916) = s141;
        a917 = (a818 + 4);
        s142 = *(a917);
        a918 = (a818 + 12);
        s143 = *(a918);
        a919 = (a824 + 4);
        a920 = *(a919);
        a921 = _mm_xor_si128(a823, a920);
        a922 = (a824 + 12);
        a923 = *(a922);
        a924 = _mm_xor_si128(a829, a923);
        a925 = (a824 + 20);
        a926 = *(a925);
        a927 = _mm_xor_si128(a835, a926);
        a928 = (a824 + 28);
        a929 = *(a928);
        a930 = _mm_xor_si128(a841, a929);
        b113 = _mm_add_epi32(a921, a924);
        b114 = _mm_add_epi32(b113, a927);
        t47 = _mm_add_epi32(b114, a930);
        t48 = _mm_sub_epi32(_mm_set_epi32(1020, 1020, 1020, 1020), t47);
        m89 = _mm_add_epi32(s142, t47);
        m90 = _mm_add_epi32(s143, t48);
        m91 = _mm_add_epi32(s142, t48);
        m92 = _mm_add_epi32(s143, t47);
        d45 = _mm_cmpgt_epi32(m89, m90);
        d46 = _mm_cmpgt_epi32(m91, m92);
        a931 = _mm_andnot_si128(d45, m89);
        a932 = _mm_and_si128(d45, m90);
        s144 = _mm_or_si128(a931, a932);
        a933 = _mm_andnot_si128(d46, m91);
        a934 = _mm_and_si128(d46, m92);
        s145 = _mm_or_si128(a933, a934);
        s146 = _mm_movemask_epi8(_mm_packs_epi16(_mm_unpacklo_epi16(_mm_packs_epi16(d45,_mm_setzero_si128()),_mm_packs_epi16(d46,_mm_setzero_si128())),_mm_setzero_si128()));
        a935 = (a851 + 4);
        *(a935) = s146;
        s147 = _mm_unpacklo_epi32(s144, s145);
        s148 = _mm_unpackhi_epi32(s144, s145);
        a936 = (a852 + 8);
        *(a936) = s147;
        a937 = (a852 + 9);
        *(a937) = s148;
        a938 = (a818 + 5);
        s149 = *(a938);
        a939 = (a818 + 13);
        s150 = *(a939);
        a940 = (a824 + 5);
        a941 = *(a940);
        a942 = _mm_xor_si128(a823, a941);
        a943 = (a824 + 13);
        a944 = *(a943);
        a945 = _mm_xor_si128(a829, a944);
        a946 = (a824 + 21);
        a947 = *(a946);
        a948 = _mm_xor_si128(a835, a947);
        a949 = (a824 + 29);
        a950 = *(a949);
        a951 = _mm_xor_si128(a841, a950);
        b115 = _mm_add_epi32(a942, a945);
        b116 = _mm_add_epi32(b115, a948);
        t49 = _mm_add_epi32(b116, a951);
        t50 = _mm_sub_epi32(_mm_set_epi32(1020, 1020, 1020, 1020), t49);
        m93 = _mm_add_epi32(s149, t49);
        m94 = _mm_add_epi32(s150, t50);
        m95 = _mm_add_epi32(s149, t50);
        m96 = _mm_add_epi32(s150, t49);
        d47 = _mm_cmpgt_epi32(m93, m94);
        d48 = _mm_cmpgt_epi32(m95, m96);
        a952 = _mm_andnot_si128(d47, m93);
        a953 = _mm_and_si128(d47, m94);
        s151 = _mm_or_si128(a952, a953);
        a954 = _mm_andnot_si128(d48, m95);
        a955 = _mm_and_si128(d48, m96);
        s152 = _mm_or_si128(a954, a955);
        s153 = _mm_movemask_epi8(_mm_packs_epi16(_mm_unpacklo_epi16(_mm_packs_epi16(d47,_mm_setzero_si128()),_mm_packs_epi16(d48,_mm_setzero_si128())),_mm_setzero_si128()));
        a956 = (a851 + 5);
        *(a956) = s153;
        s154 = _mm_unpacklo_epi32(s151, s152);
        s155 = _mm_unpackhi_epi32(s151, s152);
        a957 = (a852 + 10);
        *(a957) = s154;
        a958 = (a852 + 11);
        *(a958) = s155;
        a959 = (a818 + 6);
        s156 = *(a959);
        a960 = (a818 + 14);
        s157 = *(a960);
        a961 = (a824 + 6);
        a962 = *(a961);
        a963 = _mm_xor_si128(a823, a962);
        a964 = (a824 + 14);
        a965 = *(a964);
        a966 = _mm_xor_si128(a829, a965);
        a967 = (a824 + 22);
        a968 = *(a967);
        a969 = _mm_xor_si128(a835, a968);
        a970 = (a824 + 30);
        a971 = *(a970);
        a972 = _mm_xor_si128(a841, a971);
        b117 = _mm_add_epi32(a963, a966);
        b118 = _mm_add_epi32(b117, a969);
        t51 = _mm_add_epi32(b118, a972);
        t52 = _mm_sub_epi32(_mm_set_epi32(1020, 1020, 1020, 1020), t51);
        m97 = _mm_add_epi32(s156, t51);
        m98 = _mm_add_epi32(s157, t52);
        m99 = _mm_add_epi32(s156, t52);
        m100 = _mm_add_epi32(s157, t51);
        d49 = _mm_cmpgt_epi32(m97, m98);
        d50 = _mm_cmpgt_epi32(m99, m100);
        a973 = _mm_andnot_si128(d49, m97);
        a974 = _mm_and_si128(d49, m98);
        s158 = _mm_or_si128(a973, a974);
        a975 = _mm_andnot_si128(d50, m99);
        a976 = _mm_and_si128(d50, m100);
        s159 = _mm_or_si128(a975, a976);
        s160 = _mm_movemask_epi8(_mm_packs_epi16(_mm_unpacklo_epi16(_mm_packs_epi16(d49,_mm_setzero_si128()),_mm_packs_epi16(d50,_mm_setzero_si128())),_mm_setzero_si128()));
        a977 = (a851 + 6);
        *(a977) = s160;
        s161 = _mm_unpacklo_epi32(s158, s159);
        s162 = _mm_unpackhi_epi32(s158, s159);
        a978 = (a852 + 12);
        *(a978) = s161;
        a979 = (a852 + 13);
        *(a979) = s162;
        a980 = (a818 + 7);
        s163 = *(a980);
        a981 = (a818 + 15);
        s164 = *(a981);
        a982 = (a824 + 7);
        a983 = *(a982);
        a984 = _mm_xor_si128(a823, a983);
        a985 = (a824 + 15);
        a986 = *(a985);
        a987 = _mm_xor_si128(a829, a986);
        a988 = (a824 + 23);
        a989 = *(a988);
        a990 = _mm_xor_si128(a835, a989);
        a991 = (a824 + 31);
        a992 = *(a991);
        a993 = _mm_xor_si128(a841, a992);
        b119 = _mm_add_epi32(a984, a987);
        b120 = _mm_add_epi32(b119, a990);
        t53 = _mm_add_epi32(b120, a993);
        t54 = _mm_sub_epi32(_mm_set_epi32(1020, 1020, 1020, 1020), t53);
        m101 = _mm_add_epi32(s163, t53);
        m102 = _mm_add_epi32(s164, t54);
        m103 = _mm_add_epi32(s163, t54);
        m104 = _mm_add_epi32(s164, t53);
        d51 = _mm_cmpgt_epi32(m101, m102);
        d52 = _mm_cmpgt_epi32(m103, m104);
        a994 = _mm_andnot_si128(d51, m101);
        a995 = _mm_and_si128(d51, m102);
        s165 = _mm_or_si128(a994, a995);
        a996 = _mm_andnot_si128(d52, m103);
        a997 = _mm_and_si128(d52, m104);
        s166 = _mm_or_si128(a996, a997);
        s167 = _mm_movemask_epi8(_mm_packs_epi16(_mm_unpacklo_epi16(_mm_packs_epi16(d51,_mm_setzero_si128()),_mm_packs_epi16(d52,_mm_setzero_si128())),_mm_setzero_si128()));
        a998 = (a851 + 7);
        *(a998) = s167;
        s168 = _mm_unpacklo_epi32(s165, s166);
        s169 = _mm_unpackhi_epi32(s165, s166);
        a999 = (a852 + 14);
        *(a999) = s168;
        a1000 = (a852 + 15);
        *(a1000) = s169;
        s170 = *(a852);
        s171 = *(a936);
        a1001 = (b104 + 4);
        a1002 = *(a1001);
        a1003 = _mm_set1_epi32(a1002);
        a1004 = _mm_xor_si128(a1003, a825);
        a1005 = (b104 + 5);
        a1006 = *(a1005);
        a1007 = _mm_set1_epi32(a1006);
        a1008 = _mm_xor_si128(a1007, a831);
        a1009 = (b104 + 6);
        a1010 = *(a1009);
        a1011 = _mm_set1_epi32(a1010);
        a1012 = _mm_xor_si128(a1011, a837);
        a1013 = (b104 + 7);
        a1014 = *(a1013);
        a1015 = _mm_set1_epi32(a1014);
        a1016 = _mm_xor_si128(a1015, a843);
        b121 = _mm_add_epi32(a1004, a1008);
        b122 = _mm_add_epi32(b121, a1012);
        t55 = _mm_add_epi32(b122, a1016);
        t56 = _mm_sub_epi32(_mm_set_epi32(1020, 1020, 1020, 1020), t55);
        m105 = _mm_add_epi32(s170, t55);
        m106 = _mm_add_epi32(s171, t56);
        m107 = _mm_add_epi32(s170, t56);
        m108 = _mm_add_epi32(s171, t55);
        d53 = _mm_cmpgt_epi32(m105, m106);
        d54 = _mm_cmpgt_epi32(m107, m108);
        a1017 = _mm_andnot_si128(d53, m105);
        a1018 = _mm_and_si128(d53, m106);
        s172 = _mm_or_si128(a1017, a1018);
        a1019 = _mm_andnot_si128(d54, m107);
        a1020 = _mm_and_si128(d54, m108);
        s173 = _mm_or_si128(a1019, a1020);
        s174 = _mm_movemask_epi8(_mm_packs_epi16(_mm_unpacklo_epi16(_mm_packs_epi16(d53,_mm_setzero_si128()),_mm_packs_epi16(d54,_mm_setzero_si128())),_mm_setzero_si128()));
        a1021 = (a851 + 8);
        *(a1021) = s174;
        s175 = _mm_unpacklo_epi32(s172, s173);
        s176 = _mm_unpackhi_epi32(s172, s173);
        *(a818) = s175;
        *(a854) = s176;
        s177 = *(a853);
        s178 = *(a937);
        a1022 = _mm_xor_si128(a1003, a857);
        a1023 = _mm_xor_si128(a1007, a860);
        a1024 = _mm_xor_si128(a1011, a863);
        a1025 = _mm_xor_si128(a1015, a866);
        b123 = _mm_add_epi32(a1022, a1023);
        b124 = _mm_add_epi32(b123, a1024);
        t57 = _mm_add_epi32(b124, a1025);
        t58 = _mm_sub_epi32(_mm_set_epi32(1020, 1020, 1020, 1020), t57);
        m109 = _mm_add_epi32(s177, t57);
        m110 = _mm_add_epi32(s178, t58);
        m111 = _mm_add_epi32(s177, t58);
        m112 = _mm_add_epi32(s178, t57);
        d55 = _mm_cmpgt_epi32(m109, m110);
        d56 = _mm_cmpgt_epi32(m111, m112);
        a1026 = _mm_andnot_si128(d55, m109);
        a1027 = _mm_and_si128(d55, m110);
        s179 = _mm_or_si128(a1026, a1027);
        a1028 = _mm_andnot_si128(d56, m111);
        a1029 = _mm_and_si128(d56, m112);
        s180 = _mm_or_si128(a1028, a1029);
        s181 = _mm_movemask_epi8(_mm_packs_epi16(_mm_unpacklo_epi16(_mm_packs_epi16(d55,_mm_setzero_si128()),_mm_packs_epi16(d56,_mm_setzero_si128())),_mm_setzero_si128()));
        a1030 = (a851 + 9);
        *(a1030) = s181;
        s182 = _mm_unpacklo_epi32(s179, s180);
        s183 = _mm_unpackhi_epi32(s179, s180);
        *(a875) = s182;
        *(a896) = s183;
        s184 = *(a873);
        s185 = *(a957);
        a1031 = _mm_xor_si128(a1003, a878);
        a1032 = _mm_xor_si128(a1007, a881);
        a1033 = _mm_xor_si128(a1011, a884);
        a1034 = _mm_xor_si128(a1015, a887);
        b125 = _mm_add_epi32(a1031, a1032);
        b126 = _mm_add_epi32(b125, a1033);
        t59 = _mm_add_epi32(b126, a1034);
        t60 = _mm_sub_epi32(_mm_set_epi32(1020, 1020, 1020, 1020), t59);
        m113 = _mm_add_epi32(s184, t59);
        m114 = _mm_add_epi32(s185, t60);
        m115 = _mm_add_epi32(s184, t60);
        m116 = _mm_add_epi32(s185, t59);
        d57 = _mm_cmpgt_epi32(m113, m114);
        d58 = _mm_cmpgt_epi32(m115, m116);
        a1035 = _mm_andnot_si128(d57, m113);
        a1036 = _mm_and_si128(d57, m114);
        s186 = _mm_or_si128(a1035, a1036);
        a1037 = _mm_andnot_si128(d58, m115);
        a1038 = _mm_and_si128(d58, m116);
        s187 = _mm_or_si128(a1037, a1038);
        s188 = _mm_movemask_epi8(_mm_packs_epi16(_mm_unpacklo_epi16(_mm_packs_epi16(d57,_mm_setzero_si128()),_mm_packs_epi16(d58,_mm_setzero_si128())),_mm_setzero_si128()));
        a1039 = (a851 + 10);
        *(a1039) = s188;
        s189 = _mm_unpacklo_epi32(s186, s187);
        s190 = _mm_unpackhi_epi32(s186, s187);
        *(a917) = s189;
        *(a938) = s190;
        s191 = *(a874);
        s192 = *(a958);
        a1040 = _mm_xor_si128(a1003, a899);
        a1041 = _mm_xor_si128(a1007, a902);
        a1042 = _mm_xor_si128(a1011, a905);
        a1043 = _mm_xor_si128(a1015, a908);
        b127 = _mm_add_epi32(a1040, a1041);
        b128 = _mm_add_epi32(b127, a1042);
        t61 = _mm_add_epi32(b128, a1043);
        t62 = _mm_sub_epi32(_mm_set_epi32(1020, 1020, 1020, 1020), t61);
        m117 = _mm_add_epi32(s191, t61);
        m118 = _mm_add_epi32(s192, t62);
        m119 = _mm_add_epi32(s191, t62);
        m120 = _mm_add_epi32(s192, t61);
        d59 = _mm_cmpgt_epi32(m117, m118);
        d60 = _mm_cmpgt_epi32(m119, m120);
        a1044 = _mm_andnot_si128(d59, m117);
        a1045 = _mm_and_si128(d59, m118);
        s193 = _mm_or_si128(a1044, a1045);
        a1046 = _mm_andnot_si128(d60, m119);
        a1047 = _mm_and_si128(d60, m120);
        s194 = _mm_or_si128(a1046, a1047);
        s195 = _mm_movemask_epi8(_mm_packs_epi16(_mm_unpacklo_epi16(_mm_packs_epi16(d59,_mm_setzero_si128()),_mm_packs_epi16(d60,_mm_setzero_si128())),_mm_setzero_si128()));
        a1048 = (a851 + 11);
        *(a1048) = s195;
        s196 = _mm_unpacklo_epi32(s193, s194);
        s197 = _mm_unpackhi_epi32(s193, s194);
        *(a959) = s196;
        *(a980) = s197;
        s198 = *(a894);
        s199 = *(a978);
        a1049 = _mm_xor_si128(a1003, a920);
        a1050 = _mm_xor_si128(a1007, a923);
        a1051 = _mm_xor_si128(a1011, a926);
        a1052 = _mm_xor_si128(a1015, a929);
        b129 = _mm_add_epi32(a1049, a1050);
        b130 = _mm_add_epi32(b129, a1051);
        t63 = _mm_add_epi32(b130, a1052);
        t64 = _mm_sub_epi32(_mm_set_epi32(1020, 1020, 1020, 1020), t63);
        m121 = _mm_add_epi32(s198, t63);
        m122 = _mm_add_epi32(s199, t64);
        m123 = _mm_add_epi32(s198, t64);
        m124 = _mm_add_epi32(s199, t63);
        d61 = _mm_cmpgt_epi32(m121, m122);
        d62 = _mm_cmpgt_epi32(m123, m124);
        a1053 = _mm_andnot_si128(d61, m121);
        a1054 = _mm_and_si128(d61, m122);
        s200 = _mm_or_si128(a1053, a1054);
        a1055 = _mm_andnot_si128(d62, m123);
        a1056 = _mm_and_si128(d62, m124);
        s201 = _mm_or_si128(a1055, a1056);
        s202 = _mm_movemask_epi8(_mm_packs_epi16(_mm_unpacklo_epi16(_mm_packs_epi16(d61,_mm_setzero_si128()),_mm_packs_epi16(d62,_mm_setzero_si128())),_mm_setzero_si128()));
        a1057 = (a851 + 12);
        *(a1057) = s202;
        s203 = _mm_unpacklo_epi32(s200, s201);
        s204 = _mm_unpackhi_epi32(s200, s201);
        *(a819) = s203;
        *(a855) = s204;
        s205 = *(a895);
        s206 = *(a979);
        a1058 = _mm_xor_si128(a1003, a941);
        a1059 = _mm_xor_si128(a1007, a944);
        a1060 = _mm_xor_si128(a1011, a947);
        a1061 = _mm_xor_si128(a1015, a950);
        b131 = _mm_add_epi32(a1058, a1059);
        b132 = _mm_add_epi32(b131, a1060);
        t65 = _mm_add_epi32(b132, a1061);
        t66 = _mm_sub_epi32(_mm_set_epi32(1020, 1020, 1020, 1020), t65);
        m125 = _mm_add_epi32(s205, t65);
        m126 = _mm_add_epi32(s206, t66);
        m127 = _mm_add_epi32(s205, t66);
        m128 = _mm_add_epi32(s206, t65);
        d63 = _mm_cmpgt_epi32(m125, m126);
        d64 = _mm_cmpgt_epi32(m127, m128);
        a1062 = _mm_andnot_si128(d63, m125);
        a1063 = _mm_and_si128(d63, m126);
        s207 = _mm_or_si128(a1062, a1063);
        a1064 = _mm_andnot_si128(d64, m127);
        a1065 = _mm_and_si128(d64, m128);
        s208 = _mm_or_si128(a1064, a1065);
        s209 = _mm_movemask_epi8(_mm_packs_epi16(_mm_unpacklo_epi16(_mm_packs_epi16(d63,_mm_setzero_si128()),_mm_packs_epi16(d64,_mm_setzero_si128())),_mm_setzero_si128()));
        a1066 = (a851 + 13);
        *(a1066) = s209;
        s210 = _mm_unpacklo_epi32(s207, s208);
        s211 = _mm_unpackhi_epi32(s207, s208);
        *(a876) = s210;
        *(a897) = s211;
        s212 = *(a915);
        s213 = *(a999);
        a1067 = _mm_xor_si128(a1003, a962);
        a1068 = _mm_xor_si128(a1007, a965);
        a1069 = _mm_xor_si128(a1011, a968);
        a1070 = _mm_xor_si128(a1015, a971);
        b133 = _mm_add_epi32(a1067, a1068);
        b134 = _mm_add_epi32(b133, a1069);
        t67 = _mm_add_epi32(b134, a1070);
        t68 = _mm_sub_epi32(_mm_set_epi32(1020, 1020, 1020, 1020), t67);
        m129 = _mm_add_epi32(s212, t67);
        m130 = _mm_add_epi32(s213, t68);
        m131 = _mm_add_epi32(s212, t68);
        m132 = _mm_add_epi32(s213, t67);
        d65 = _mm_cmpgt_epi32(m129, m130);
        d66 = _mm_cmpgt_epi32(m131, m132);
        a1071 = _mm_andnot_si128(d65, m129);
        a1072 = _mm_and_si128(d65, m130);
        s214 = _mm_or_si128(a1071, a1072);
        a1073 = _mm_andnot_si128(d66, m131);
        a1074 = _mm_and_si128(d66, m132);
        s215 = _mm_or_si128(a1073, a1074);
        s216 = _mm_movemask_epi8(_mm_packs_epi16(_mm_unpacklo_epi16(_mm_packs_epi16(d65,_mm_setzero_si128()),_mm_packs_epi16(d66,_mm_setzero_si128())),_mm_setzero_si128()));
        a1075 = (a851 + 14);
        *(a1075) = s216;
        s217 = _mm_unpacklo_epi32(s214, s215);
        s218 = _mm_unpackhi_epi32(s214, s215);
        *(a918) = s217;
        *(a939) = s218;
        s219 = *(a916);
        s220 = *(a1000);
        a1076 = _mm_xor_si128(a1003, a983);
        a1077 = _mm_xor_si128(a1007, a986);
        a1078 = _mm_xor_si128(a1011, a989);
        a1079 = _mm_xor_si128(a1015, a992);
        b135 = _mm_add_epi32(a1076, a1077);
        b136 = _mm_add_epi32(b135, a1078);
        t69 = _mm_add_epi32(b136, a1079);
        t70 = _mm_sub_epi32(_mm_set_epi32(1020, 1020, 1020, 1020), t69);
        m133 = _mm_add_epi32(s219, t69);
        m134 = _mm_add_epi32(s220, t70);
        m135 = _mm_add_epi32(s219, t70);
        m136 = _mm_add_epi32(s220, t69);
        d67 = _mm_cmpgt_epi32(m133, m134);
        d68 = _mm_cmpgt_epi32(m135, m136);
        a1080 = _mm_andnot_si128(d67, m133);
        a1081 = _mm_and_si128(d67, m134);
        s221 = _mm_or_si128(a1080, a1081);
        a1082 = _mm_andnot_si128(d68, m135);
        a1083 = _mm_and_si128(d68, m136);
        s222 = _mm_or_si128(a1082, a1083);
        s223 = _mm_movemask_epi8(_mm_packs_epi16(_mm_unpacklo_epi16(_mm_packs_epi16(d67,_mm_setzero_si128()),_mm_packs_epi16(d68,_mm_setzero_si128())),_mm_setzero_si128()));
        a1084 = (a851 + 15);
        *(a1084) = s223;
        s224 = _mm_unpacklo_epi32(s221, s222);
        s225 = _mm_unpackhi_epi32(s221, s222);
        *(a960) = s224;
        *(a981) = s225;
    }
    /* skip */
}
